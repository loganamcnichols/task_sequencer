{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Sequencer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i>\"Sometimes when you innovate, you make mistakes. It is best to admit them quickly, and get on with improving your other innovations.\"<i> -Steve Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tool which will calculate the optimal order to approach tasks in a project where there are several different tasks that need to be done that have a certain probability of failing and will take a certain time to complete.\n",
    "\n",
    "When we are uncertain about the feasibility of a project, we should strive to get as much information about the difficulty as quickly as possible. This suggests starting with tasks with a high failure rate.\n",
    "\n",
    "The idea behind this approach is and some other useful information is discussed here. https://cs.stanford.edu/~jsteinhardt/ResearchasaStochasticDecisionProcess.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import ipysheet\n",
    "import pandas as pd\n",
    "from itertools import permutations\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['lines.linewidth'] = 2.0\n",
    "from IPython.display import Markdown, display, clear_output, FileLink\n",
    "\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "def df_from_sheet(sheet):\n",
    "    '''Converts the sheet to a compact dataframe'''\n",
    "    df = ipysheet.to_dataframe(sheet)\n",
    "    df = fill_blanks(df)\n",
    "    df = trim_df(df)\n",
    "    df = switch_from_names(df)\n",
    "    df = nums_to_float(df)\n",
    "    df = switch_to_names(df)\n",
    "    return df\n",
    "\n",
    "def switch_to_names(df):\n",
    "    '''Converts indicies in the dependency cols\n",
    "    to their corresponding task names'''\n",
    "    df.iloc[:,3:] = df.iloc[:,3:].replace(\n",
    "        dict(zip(df.index + 1, df['task'])))\n",
    "    return df\n",
    "\n",
    "def switch_from_names(df):\n",
    "    '''Converts the task names  in the dependency \n",
    "    cols to their coresponding indicies'''\n",
    "    df.iloc[:,3:] = df.iloc[:,3:].replace(\n",
    "        dict(zip(df['task'], df.index + 1)))\n",
    "    return df\n",
    "\n",
    "def fill_blanks(df):\n",
    "    '''Replaces NaN and empty values with 0s'''\n",
    "    df.fillna(0, inplace=True)\n",
    "    df.replace([\"\", \"0\"], 0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def trim_df(df):\n",
    "    '''Removes rows and columns that dont contain\n",
    "    any information'''\n",
    "    zero_row_bool = (df.values==0).all(axis=1)\n",
    "    zero_row_loc = np.where(zero_row_bool)[0]\n",
    "    if zero_row_loc.size == 0:\n",
    "        first_zero_row=df.shape[0]\n",
    "    else:\n",
    "        first_zero_row = zero_row_loc[0]\n",
    "    zero_col_bool = (df.values==0).all(axis=0)\n",
    "    zero_col_loc = np.where(zero_col_bool)[0]\n",
    "    if zero_col_loc.size == 0:\n",
    "        first_zero_col = df.shape[1]\n",
    "    else:\n",
    "        first_zero_col = zero_col_loc[0]\n",
    "    return df.iloc[:first_zero_row,:first_zero_col]\n",
    "    \n",
    "def nums_to_float(df):\n",
    "    '''Converts all numerical entries\n",
    "    to floats'''\n",
    "    df.iloc[:,1:] = df.iloc[:,1:].astype(float)\n",
    "    return df\n",
    "\n",
    "def build_sheet(task_report=\"task_sheet.csv\",\n",
    "               rows=10, cols=10):\n",
    "    '''Creates the task dependency sheet'''\n",
    "    labels = (['task', 'time', 'probability'] \n",
    "              + [\"d\" + str(i + 1) \n",
    "                 for i in range(cols - 3)])\n",
    "    sheet = sheet_from_df(task_report, rows, \n",
    "                          cols, labels)\n",
    "    if sheet:\n",
    "        return sheet\n",
    "    sheet = sheet_from_scratch(rows, cols, labels)\n",
    "    return sheet\n",
    "\n",
    "def sheet_from_df(task_report, rows, \n",
    "                  cols, labels):\n",
    "    '''Returns a dataframe from task_report if\n",
    "    task_report is in the working directory. Otherwise\n",
    "    returns None.'''\n",
    "    try:\n",
    "        sheet = ipysheet.sheet(\n",
    "            rows=rows,\n",
    "            columns=cols,\n",
    "            column_headers=labels)\n",
    "        df = pd.read_csv(task_report)\n",
    "        df = rid_zeros(df)\n",
    "        data = np.empty([rows, cols], dtype=object)\n",
    "        data[:df.shape[0], :df.shape[1]] = df.values\n",
    "        ipysheet.cell_range(data)\n",
    "        return sheet\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def rid_zeros(df):\n",
    "    '''Converts the task names  in the dependency \n",
    "    cols to their coresponding indicies'''\n",
    "    df.iloc[:,3:] = df.iloc[:,3:].replace({'0.0' : None})\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def sheet_from_scratch(rows, cols, labels):\n",
    "    '''Generates a sheet with all empty values'''\n",
    "    sheet = ipysheet.sheet(\n",
    "        rows=rows,\n",
    "        columns=cols,\n",
    "        column_headers=labels)\n",
    "    data = [['' for i in range(cols)] \n",
    "            for i in range(rows)]\n",
    "    ipysheet.cell_range(data)\n",
    "    return sheet\n",
    "\n",
    "def gen_perms(df):\n",
    "    '''Creates a list of all permutations of the\n",
    "    rows of the dataframe (indexing starting at 1)'''\n",
    "    rows=df.shape[0]\n",
    "    return permutations(range(1,rows+1))\n",
    "\n",
    "def validate_perms(perms, deps):\n",
    "    '''Returns the rows in perms which dont\n",
    "    violate a dependency'''\n",
    "    valid_perms = []\n",
    "    for perm in perms:\n",
    "        if check_perm(perm, deps) == True:\n",
    "            valid_perms.append(perm)\n",
    "    return valid_perms\n",
    "\n",
    "def check_perm(perm, deps):\n",
    "    '''Returns True or False according to whether\n",
    "    perm violates a dependency'''\n",
    "    prev_ind = [0]\n",
    "    for index in perm:\n",
    "        prev_ind.append(index)\n",
    "        dep = deps[index-1, :]\n",
    "        sub_true = all(elem in prev_ind for elem in dep)\n",
    "        if sub_true is False:\n",
    "            return False\n",
    "        elif index == perm[-1]:\n",
    "            return True\n",
    "\n",
    "def sort_rates(times, probs):\n",
    "    '''Returns an order list of the\n",
    "    failure rates'''\n",
    "    return (np.flip(np.argsort(\n",
    "        1/times*np.log(1/(1-probs)))) + 1)\n",
    "        \n",
    "def get_expected_times(perms, df):\n",
    "    '''Calculates the expected time according to the\n",
    "    equation in appendix A'''\n",
    "    sums = []\n",
    "    for perm in perms:\n",
    "        prob_col = df['probability'][np.array(perm)-1].values.astype(float)\n",
    "        prob_comp = 1 - prob_col\n",
    "        prob_mat = expand_to_lower_tri_mat(prob_comp)\n",
    "        prod_arr = prob_prod_arr(prob_mat, prob_col)\n",
    "        time_col = df['time'][np.array(perm) - 1].values.astype(float)\n",
    "        time_mat = expand_to_lower_tri_mat(time_col)\n",
    "        sum_arr = sum_times(time_mat)\n",
    "        sums.append(expected_time_eq(prod_arr,\n",
    "                                     sum_arr, time_col,\n",
    "                                     prob_col, prob_comp))\n",
    "    return sums\n",
    "\n",
    "\n",
    "def expected_time_eq(prod_arr, sum_arr, time_col, prob_col,\n",
    "                     prob_comp):\n",
    "    prob_succ = np.prod(prob_comp)\n",
    "    total_time = np.sum(time_col)\n",
    "    failure_times_by_task = ((np.log((prob_comp)**(prob_comp)) \n",
    "                        + prob_col)\n",
    "                        /np.log((1/prob_comp)**prob_col))\n",
    "    for i,x in enumerate(failure_times_by_task):\n",
    "        if prob_col[i]==0:\n",
    "            failure_times_by_task[i] = 1/2\n",
    "    exp_time_given_fail = np.sum(prod_arr*(sum_arr + time_col\n",
    "                                           *failure_times_by_task))\n",
    "    prob_fail = 1 - np.prod(prob_comp)\n",
    "    return (prob_succ*total_time \n",
    "            + exp_time_given_fail*prob_fail)\n",
    "\n",
    "def expand_to_lower_tri_mat(arr):\n",
    "    '''Converts arr to a lower triangular matrix.\n",
    "    e.g. [1,2,3] => [[1,0,0]\n",
    "                     [1,2,0]\n",
    "                     [1,2,3]]'''\n",
    "    two_d_arr = np.expand_dims((arr), 0)\n",
    "    square_mat = np.repeat(two_d_arr,\n",
    "                             repeats=arr.shape[0],\n",
    "                             axis=0)\n",
    "    return np.tril(square_mat)\n",
    "    \n",
    "def prob_prod_arr(prob_mat, prob_col):\n",
    "    '''Returns the product array that will satisfy the\n",
    "    equation in the appendix'''\n",
    "    np.fill_diagonal(prob_mat, 0)\n",
    "    ones = np.triu(np.ones(np.shape(prob_mat)))\n",
    "    np.fill_diagonal(ones, 0)\n",
    "    return np.prod(ones + prob_mat + np.diag(prob_col), 1)\n",
    "\n",
    "def sum_times(time_mat):\n",
    "    '''Returns an array of sums from\n",
    "    a lower triangular matrix'''\n",
    "    np.fill_diagonal(time_mat, 0)\n",
    "    return np.sum(time_mat, 1)\n",
    "\n",
    "def adj_transposes(arr):\n",
    "    \"\"\"returns a matrix where each row\n",
    "    is one of the n-1 adjacent transposes\"\"\"\n",
    "    reps_mat = repeat_array_as_matrix(arr, len(arr)-1)\n",
    "    for i in range(len(arr)-1):\n",
    "        ith_row = reps_mat[i,:]\n",
    "        ith_row[i], ith_row[i+1] = ith_row[i+1], ith_row[i]\n",
    "    return reps_mat\n",
    "\n",
    "def find_kids(row, arr, deps):\n",
    "    '''Returns the inidicies of srtd_rates where\n",
    "    the dependents of task in \"row\" are located'''\n",
    "    child_rows = np.argwhere(deps==row)[:,0] + 1\n",
    "    child_loc = np.where(np.in1d(arr, child_rows))[0]\n",
    "    return child_loc\n",
    "\n",
    "def repeat_array_as_matrix(arr, reps):\n",
    "    '''e.g. array([1,2]) to array([[1,2],\n",
    "                                    [1,2]])'''\n",
    "    matrix_head = np.expand_dims(arr, axis=0)\n",
    "    return np.repeat(matrix_head,\n",
    "                      repeats=reps,\n",
    "                        axis=0)\n",
    "\n",
    "def find_parents(row, arr, deps):\n",
    "    '''Returns the inidicies of arr where\n",
    "    the tasks that task in row is dependent on\n",
    "    are located'''\n",
    "    dep = deps[row-1] #minus 1 cause index\n",
    "    parent_rows = dep[np.nonzero(dep)] #rid zeros\n",
    "    parent_loc = np.where(np.in1d(arr, parent_rows))[0]\n",
    "    return parent_loc\n",
    "\n",
    "def calc_disarray(arr, deps):\n",
    "    '''returns a number according to how disarrayed\n",
    "    arr is'''\n",
    "    total_disarray = 0\n",
    "    for task_loc, task in enumerate(arr):\n",
    "        task_kids_loc = find_kids(task, arr, deps)\n",
    "        task_pars_loc = find_parents(task, arr, deps)\n",
    "        total_disarray += element_disarray(task_kids_loc,\n",
    "                                           task_pars_loc,\n",
    "                                           task_loc)\n",
    "    return total_disarray\n",
    "\n",
    "def find_least_disarrayed(mat, deps):\n",
    "    '''Returns the rows of mat that have the\n",
    "    lowest disarray score'''\n",
    "    disarray_counts = np.zeros(mat.shape[0])\n",
    "    for i, row in enumerate(mat):\n",
    "        disarray_counts[i] = calc_disarray(row, deps)\n",
    "    min_disarray = np.amin(disarray_counts)\n",
    "    min_ind = np.where(disarray_counts==min_disarray)[0]\n",
    "    return mat[min_ind,:]\n",
    "\n",
    "def element_disarray(kid_loc, par_loc, loc):\n",
    "    '''Returns a number according to how \"out of place\"\n",
    "    an element is'''\n",
    "    kids_to_left = np.extract(kid_loc<loc, kid_loc)\n",
    "    pars_to_right = np.extract(par_loc>loc, par_loc)\n",
    "    return (np.sum(loc - kids_to_left) + \n",
    "            np.sum(pars_to_right - loc))\n",
    "\n",
    "def check_unique(mat, prev):\n",
    "    '''Removes the rows in mat that\n",
    "    are also in prev'''\n",
    "    for i, row in enumerate(mat):\n",
    "        if (prev==row).all(axis=1).any():\n",
    "            mat[i,:] = np.zeros(\n",
    "                mat.shape[1])\n",
    "    mat = mat[~np.all(\n",
    "        mat==0, axis=1)]\n",
    "    return mat\n",
    "\n",
    "def quick_best_order(arr, df, deps, count, prev):\n",
    "    '''Returns an approximation for the optimal\n",
    "    order.'''\n",
    "    count += 1\n",
    "    transposes = adj_transposes(arr)\n",
    "    transposes = check_unique(transposes, prev)\n",
    "    least_disarrayed = find_least_disarrayed(transposes, deps)\n",
    "    expected_times = get_expected_times(least_disarrayed, df)\n",
    "    best = least_disarrayed[np.argmin(expected_times)]\n",
    "    prev = np.append(prev, np.expand_dims(best, 0), 0)\n",
    "    if check_perm(best, deps)==True:\n",
    "        return best\n",
    "    elif count<50:\n",
    "        return quick_best_order(best, df, deps, count, prev)\n",
    "    else:\n",
    "        return (\"Error: Make sure dependencies don't produce\"\n",
    "                + \" a contradiction.\")\n",
    "\n",
    "def present_list(arr, df):\n",
    "    name_list = []\n",
    "    index_to_name = dict(zip( df.index + 1, df['task']))\n",
    "    for index in arr:\n",
    "        name_list.append(index_to_name[index])\n",
    "    return pd.DataFrame(name_list, columns=[\"Tasks\"])\n",
    "\n",
    "    \n",
    "def plot_fig(sorted_sums):\n",
    "    fig, axs = plt.subplots()\n",
    "    axs.plot(np.arange(len(sorted_sums)), sorted_sums, color='black', ls='--')\n",
    "    plt.xticks([])\n",
    "    axs.set_title('Distribution of Expected Time')\n",
    "    plt.show()\n",
    "\n",
    "def main(df):\n",
    "    df = switch_from_names(df)\n",
    "    deps = df.filter(like='d').values\n",
    "    times = df['time'].values.astype(float)\n",
    "    probs = df['probability'].values.astype(float)\n",
    "    srtd_rates = sort_rates(times, probs)\n",
    "    prev = np.zeros([1,df.shape[0]])\n",
    "    rows = df.shape[0]\n",
    "    if rows < 10:\n",
    "        perms = gen_perms(df)\n",
    "        valid_perms = validate_perms(perms, deps)\n",
    "        sums = get_expected_times(valid_perms, df)\n",
    "        sorted_sums = np.sort(sums)\n",
    "        best_order = valid_perms[np.argmin(sums)]\n",
    "        plot_fig(sorted_sums)\n",
    "        printmd(\"##### the optimal order is \")\n",
    "        display(present_list(best_order, df))\n",
    "        printmd(\"##### and the expected time is\")\n",
    "        printmd(\"##### \" + str(sorted_sums[0]) + \".\")\n",
    "\n",
    "    else:\n",
    "        best = quick_best_order(srtd_rates, df, deps, 0, prev)\n",
    "        print('The optimal order is') \n",
    "        display(present_list(best, df))\n",
    "        print(\"and the expected time is\")\n",
    "        display(get_expected_times(\n",
    "                    np.expand_dims(best, 0), df)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e00b8d6cbe94ab3b5f7a9c33c932917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.csv', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myupload = ipywidgets.FileUpload(accept='.csv', multiple=False)\n",
    "display(myupload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8529fe2d63ba4a51803bbc6092309a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Build Sheet', style=ButtonStyle()), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sheet_butt = ipywidgets.Button(description='Build Sheet')\n",
    "out = ipywidgets.Output()\n",
    "sheet = build_sheet()\n",
    "\n",
    "def sheet_butt_func(_):\n",
    "    global sheet\n",
    "    with out:\n",
    "        try:\n",
    "            clear_output()\n",
    "            uploaded_filename = next(iter(myupload.value))\n",
    "            content = myupload.value[uploaded_filename]['content']\n",
    "            with open('task_sheet.csv', 'wb') as f: f.write(content)\n",
    "            sheet = build_sheet()\n",
    "            display(sheet)\n",
    "        except:\n",
    "            sheet = build_sheet()\n",
    "            display(sheet)\n",
    "sheet_butt.on_click(sheet_butt_func)\n",
    "display(ipywidgets.VBox([sheet_butt,out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c556fb7018104af79c27a8ab475b2a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Run', style=ButtonStyle()),)), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = ipywidgets.Button(description='Run')\n",
    "out = ipywidgets.Output()\n",
    "def run_program(_):\n",
    "    with out:\n",
    "        df = df_from_sheet(sheet)\n",
    "        df.to_csv('task_sheet.csv', index=False)\n",
    "        local_file = FileLink('./task_sheet.csv', result_html_prefix=\"Click here to download the sheet: \")\n",
    "        return main(df), display(local_file)\n",
    "        \n",
    "run.on_click(run_program)\n",
    "buttons = ipywidgets.HBox([run])\n",
    "ipywidgets.VBox([buttons,out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to calculate the expected time to termination for a given sequence of $n$ tasks. We either terminate by completing all of our tasks or failing on one of them. Let $T$ be the random variable denoting time until termination. $S$ be a random variable indicating whether we have succeeded or not.\n",
    "From the law of total expectation, \n",
    "\n",
    "$$\n",
    "\\text{E}[T] = \\text{E}[\\text{E}[T \\vert S]] = \\text{P}(S = 1)\\text{E}[T \\vert S = 1] + \\text{P}(S = 0)\\text{E}[T \\vert S = 0].\n",
    "$$\n",
    "\n",
    "To start we will focus our calculation on $\\text{E}[T \\vert S = 0]$. Let $L_i$ be the event that we fail on the $i^{\\text{th}}$ task, for $i \\in \\{ 1, \\dots, n\\}$. Observe that the possible events given we fail are $L_1, \\dots, L_n$. Thus, $L_1, \\dots, L_n$ partitions $\\{S = 0\\}$. This means that we can apply the law of total expectation again to yield\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{E}[T \\vert S = 0] = \\text{P}(L_1)\\text{E}[T \\vert L_1] + \\dots + \\text{P}(L_n)\\text{E}[T \\vert L_n].\n",
    "$$\n",
    "\n",
    "$\\text{P}(L_i)$ is determined by the probability of getting to task $i$ and the probability of failing at task $i$. It can be calculated with\n",
    "\n",
    "$$\n",
    "\\text{P}(L_i) = p_i \\prod_{k = 1}^{i - 1} (1 - p_{k}).\n",
    "$$\n",
    "\n",
    "Next, to calculate $\\text{E}[T \\vert L_i]$, let the starting time $t_{s}$ denote the time at which we start the $i^{\\text{th}}$ task. Let $t_{i}$ denote the time the $i^{\\text{th}}$ task takes us. Let $T_{i}$ be the random variable denoting the time spent on task $i$ given that we fail on task $i$. Suppose that the task fails at a rate $\\lambda$ which is independent of how long we have been working on it. Then $f(t) = \\lambda e^{-\\lambda t}$ is the probability density function for failure time if the task is allowed to continue indefinately until we fail. We have assumed that the task will fail before $t_{i}$. It therefore follows that the probability density function for $T_{i}$ is $f(t \\vert t< t_{i})$. This function has is given by\n",
    "\n",
    "$$\n",
    "f(t \\vert t \\leq t_{i})= \\begin{cases}\n",
    "\\frac{1}{A}\\lambda e^{-\\lambda t}, \\hspace{1cm} 0 \\leq t \\leq t_{i}, \\\\\n",
    "0, \\hspace{1.8cm} \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Where $A$ denotes the area under the curve of $f(t)$ from $0$ to $t_{i}$. To calculate $A$, we have\n",
    "\n",
    "$$\n",
    "A = \\int_0^{t_{i}} \\lambda e^{-\\lambda t} dt = 1 - e^{-\\lambda t_{i}}.\n",
    "$$\n",
    "\n",
    "To calculate $\\text{E}[T]$ we now have\n",
    "\n",
    "$$\n",
    "\\text{E}[T \\vert L_i] = t_0 + \\frac{1}{ 1 - e^{-\\lambda t_{i}}} \\int_0^{t_{i}} \\lambda t e^{-\\lambda t} dt,\n",
    "$$\n",
    "\n",
    "which after some simplification yeilds\n",
    "\n",
    "$$\n",
    "\\text{E}[T \\vert L_i] = t_0 + \\frac{1 - t_{i} \\lambda e^{-\\lambda t_{i}} - e^{-\\lambda t_{i}}}{\\lambda(1 - e^{-\\lambda t_{i}})}.\n",
    "$$\n",
    "\n",
    "$\\lambda$ is currently an unknown value. The values we are given are $t_i$ and the probability of failure $p_i$. We need to write $\\lambda$ in terms of these known quantities. This can be done with the following equation.\n",
    "\n",
    "$$\n",
    "1 - e^{- \\lambda t_i} = p_{i},\n",
    "$$\n",
    "\n",
    "which yields\n",
    "\n",
    "$$\n",
    "\\lambda = \\frac{1}{t_i}\\ln \\Big{(}\\frac{1}{1 - p_{i}}\\Big{)}\n",
    "$$\n",
    "\n",
    "By substituting this value of $\\lambda$ into the above equation and simplifying we get\n",
    "\n",
    "$$\n",
    "\\text{E}[T \\vert L_i] = t_0 + \\frac{t_i\\big{(}\\ln\\big{(}(1 - p_i)^{1 - p}\\big{)} + p_i\\big{)}}{\\ln\\Big{(}\\big{(}\\frac{1}{1-p_{i}}\\big{)}^{p_{i}}\\Big{)}}.\n",
    "$$\n",
    "\n",
    "Thus, $\\text{P}(L_i)\\text{E}[T \\vert L_i]$ is given by\n",
    "\n",
    "$$\n",
    "\\text{P}(L_i)\\text{E}[T \\vert L_i] = p_i \\prod_{k = 1}^{i - 1} (1 - p_{k}) \\Bigg{(}t_0 + \\frac{t_i\\big{(}\\ln\\big{(}(1 - p_i)^{1 - p}\\big{)} + p_i\\big{)}}{\\ln\\Big{(}\\big{(}\\frac{1}{1-p_{i}}\\big{)}^{p_{i}}\\Big{)}} \\Bigg{)}.\n",
    "$$\n",
    "\n",
    "Note that for each $i \\in \\{1, \\dots n\\}$, $t_0$ is the time to complete the $1^{\\text{st}}$ through $i - 1^{\\text{th}}$ task. Then we can write $t_0$ as\n",
    "\n",
    "$$\n",
    "t_0 = \\sum_{j = 1}^{i - 1} t_j.\n",
    "$$\n",
    "\n",
    "This implies that our final equation for $\\text{P}(L_i)\\text{E}[T \\vert L_i]$ is given by\n",
    "\n",
    "$$\n",
    "\\text{P}(L_i)\\text{E}[T \\vert L_i] = p_i \\prod_{k = 1}^{i - 1} (1 - p_{k}) \\Bigg{(}\\sum_{j = 1}^{i - 1} t_j + \\frac{t_i\\big{(}\\ln\\big{(}(1 - p_i)^{1 - p}\\big{)} + p_i\\big{)}}{\\ln\\Big{(}\\big{(}\\frac{1}{1-p_{i}}\\big{)}^{p_{i}}\\Big{)}} \\Bigg{)}.\n",
    "$$\n",
    "\n",
    "To find $\\text{E}[T \\vert S = 1]$, we must simply sum through all of the terms.\n",
    "\n",
    "$$\n",
    "\\text{E}[T \\vert S = 1] = \\sum_{i = 1}^n \\Bigg{(}p_i \\prod_{k = 1}^{i - 1} (1 - p_{k}) \\Bigg{(}\\sum_{j = 1}^{i - 1} t_j + \\frac{t_i\\big{(}\\ln\\big{(}(1 - p_i)^{1 - p}\\big{)} + p_i\\big{)}}{\\ln\\Big{(}\\big{(}\\frac{1}{1-p_{i}}\\big{)}^{p_{i}}\\Big{)}} \\Bigg{)} \\Bigg{)}\n",
    "$$\n",
    "\n",
    "Next, by looking at the complement of $\\text{P}(S = 0)$ we have\n",
    "\n",
    "$$\n",
    "\\text{P}(S = 0) = 1 - \\text{P}(S = 1) = 1 - \\prod_{i = 1}^{n} (1 - p_i).\n",
    "$$\n",
    "\n",
    "$\\text{E}[T \\vert S = 1]$ is simply the expected time to success, which is simply the sum of the expected times to complete each task given by\n",
    "\n",
    "$$\n",
    "\\text{E}[T \\vert S = 1] = \\sum_{i = 1}^n t_i\n",
    "$$\n",
    "\n",
    "Putting all of this together, we find\n",
    "\n",
    "$$\n",
    "\\text{E}[T] = \\Big{(}1 - \\prod_{i = 1}^{n} (1 - p_i)\\Big{)}\\sum_{i = 1}^n t_i + \\prod_{i = 1}^{n} (1 - p_i) \\Bigg{(} \\sum_{i = 1}^n \\Bigg{(} p_i \\prod_{k = 1}^{i - 1} (1 - p_{k}) \\Bigg{(}\\sum_{j = 1}^{i - 1} t_j + \\frac{t_i\\big{(}\\ln\\big{(}(1 - p_i)^{1 - p}\\big{)} + p_i\\big{)}}{\\ln\\Big{(}\\big{(}\\frac{1}{1-p_{i}}\\big{)}^{p_{i}}\\Big{)}} \\Bigg{)} \\Bigg{)} \\Bigg{)}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
