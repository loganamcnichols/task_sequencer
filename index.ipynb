{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task Sequencer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tool will calculate the optimal order to attempt tasks in a project where each task has some probability of failing.\n",
    "\n",
    "When we are uncertain about the feasibility of a project, we should strive to get as much information about the difficulty as quickly as possible. This suggests that we should start with tasks with a high failure rate.\n",
    "\n",
    "For a deeper discussion of this approach and related techiques see <a href=\"https://cs.stanford.edu/~jsteinhardt/ResearchasaStochasticDecisionProcess.html\">Research as a Stochastic Decision Process</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "import ipysheet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import permutations\n",
    "from IPython.display import Markdown, display, clear_output, FileLink\n",
    "from symbulate import RV, Exponential\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['lines.linewidth'] = 2.0\n",
    "\n",
    "\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "def df_from_sheet(sheet):\n",
    "    '''Converts the sheet to a compact dataframe'''\n",
    "    df = ipysheet.to_dataframe(sheet)\n",
    "    df = fill_blanks(df)\n",
    "    df = trim_df(df)\n",
    "    df = switch_from_names(df)\n",
    "    df = nums_to_float(df)\n",
    "    df = switch_to_names(df)\n",
    "    return df\n",
    "\n",
    "def switch_to_names(df):\n",
    "    '''Converts indicies in the dependency cols\n",
    "    to their corresponding task names'''\n",
    "    df.iloc[:,3:] = df.iloc[:,3:].replace(\n",
    "        row_to_name_dict(df))\n",
    "    return df\n",
    "\n",
    "def switch_from_names(df):\n",
    "    '''Converts the task names in the dependency \n",
    "    cols to their coresponding indicies'''\n",
    "    df.iloc[:,3:] = df.iloc[:,3:].replace(\n",
    "        name_to_row_dict(df))\n",
    "    return df\n",
    "\n",
    "def name_to_row_dict(df):\n",
    "    return dict(zip(df['Task'], df.index + 1))\n",
    "\n",
    "def row_to_name_dict(df):\n",
    "    return dict(zip(df.index + 1, df['Task']))\n",
    "\n",
    "def fill_blanks(df):\n",
    "    '''Replaces NaN and empty values with 0s'''\n",
    "    df.fillna(0, inplace=True)\n",
    "    df.replace([\"\", \"0\"], 0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def trim_df(df):\n",
    "    '''Removes rows and columns that only contain zeros'''\n",
    "    nonzero_shape = [0, 0] # store dims of portion of df w/out 0 rows/cols\n",
    "    for index, axis in enumerate((1,0)):\n",
    "        zero_bool = (df.values==0).all(axis=axis)\n",
    "        zero_locs = np.where(zero_bool)[0]\n",
    "        if zero_locs.size == 0:\n",
    "            nonzero_shape[index] = df.shape[index] - 1 \n",
    "            # -1 b/c using nonzero_shape to index\n",
    "        else:\n",
    "            nonzero_shape[index] = zero_locs[0]\n",
    "    return df.iloc[:nonzero_shape[0], :nonzero_shape[1]]\n",
    "\n",
    "def nums_to_float(df):\n",
    "    '''Converts all numerical entries\n",
    "    to floats'''\n",
    "    df.iloc[:,1:] = df.iloc[:,1:].astype(float)\n",
    "    return df\n",
    "\n",
    "def build_sheet(task_report=\"task_sheet.csv\",\n",
    "               rows=10, cols=10):\n",
    "    '''Creates the task dependency sheet'''\n",
    "    labels = (['Task', 'Time', 'Probability'] \n",
    "              + [\"D\" + str(i + 1) \n",
    "                 for i in range(cols - 3)])\n",
    "    sheet = sheet_from_df(task_report, rows, \n",
    "                          cols, labels)\n",
    "    if sheet:\n",
    "        return sheet\n",
    "    sheet = sheet_from_scratch(rows, cols, labels)\n",
    "    return sheet\n",
    "\n",
    "def sheet_from_df(task_report, rows, \n",
    "                  cols, labels):\n",
    "    '''Returns a dataframe from task_report if\n",
    "    task_report is in the working directory. Otherwise\n",
    "    returns None.'''\n",
    "    try:\n",
    "        sheet = ipysheet.sheet(\n",
    "            rows=rows,\n",
    "            columns=cols,\n",
    "            column_headers=labels)\n",
    "        df = pd.read_csv(task_report)\n",
    "        df = rid_zeros(df)\n",
    "        data = np.empty([rows, cols], dtype=object)\n",
    "        data[:df.shape[0], :df.shape[1]] = df.values\n",
    "        ipysheet.cell_range(data)\n",
    "        return sheet\n",
    "    except OSError:\n",
    "        return None\n",
    "\n",
    "def rid_zeros(df):\n",
    "    '''Converts the task names  in the dependency \n",
    "    cols to their coresponding indicies'''\n",
    "    df.iloc[:,3:] = df.iloc[:,3:].replace({'0.0' : None})\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def sheet_from_scratch(rows, cols, labels):\n",
    "    '''Generates a sheet with all empty values'''\n",
    "    sheet = ipysheet.sheet(\n",
    "        rows=rows,\n",
    "        columns=cols,\n",
    "        column_headers=labels)\n",
    "    data = [['' for i in range(cols)] \n",
    "            for i in range(rows)]\n",
    "    ipysheet.cell_range(data)\n",
    "    return sheet\n",
    "\n",
    "def gen_perms(df):\n",
    "    '''Creates a list of all permutations of the\n",
    "    rows of the dataframe (indexing starting at 1)'''\n",
    "    rows=df.shape[0]\n",
    "    return permutations(range(1,rows+1))\n",
    "\n",
    "def validate_perms(perms, deps):\n",
    "    '''Returns the rows in perms which dont\n",
    "    violate a dependency'''\n",
    "    valid_perms = []\n",
    "    for perm in perms:\n",
    "        if check_perm(perm, deps) == True:\n",
    "            valid_perms.append(perm)\n",
    "    return valid_perms\n",
    "\n",
    "def check_perm(perm, deps):\n",
    "    '''Returns True or False according to whether\n",
    "    perm violates a dependency'''\n",
    "    prev_ind = [0]\n",
    "    for index in perm:\n",
    "        prev_ind.append(index)\n",
    "        dep = deps[index-1, :]\n",
    "        if not all(elem in prev_ind for elem in dep):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def sort_rates(times, probs):\n",
    "    '''Returns an order list of the\n",
    "    failure rates (called lambda in the\n",
    "    appendix)'''\n",
    "    return (np.flip(np.argsort(\n",
    "        1/times*np.log(1/(1-probs)))) + 1)\n",
    "        \n",
    "def get_expected_times(perms, df):\n",
    "    '''Calculates the expected time for each\n",
    "    order of the tasks according to the\n",
    "    equation in appendix A'''\n",
    "    sums = []\n",
    "    for perm in perms:\n",
    "        prob_col = df['Probability'][np.array(perm)-1].values.astype(float)\n",
    "        prob_comp = 1 - prob_col\n",
    "        prob_mat = expand_to_lower_tri_mat(prob_comp)\n",
    "        prod_arr = prob_prod_arr(prob_mat, prob_col)\n",
    "        time_col = df['Time'][np.array(perm) - 1].values.astype(float)\n",
    "        time_mat = expand_to_lower_tri_mat(time_col)\n",
    "        sum_arr = sum_times(time_mat)\n",
    "        sums.append(expected_time_eq(prod_arr,\n",
    "                                     sum_arr, time_col,\n",
    "                                     prob_col, prob_comp))\n",
    "    return sums\n",
    "\n",
    "\n",
    "def expected_time_eq(prod_arr, sum_arr, time_col, prob_col,\n",
    "                     prob_comp):\n",
    "    prob_succ = np.prod(prob_comp)\n",
    "    total_time = np.sum(time_col)\n",
    "    exp_time_given_fail_on_task = (sum_arr\n",
    "                                   - time_col/prob_col\n",
    "                                   + time_col/np.log(1/(1 - prob_col))\n",
    "                                   + time_col)\n",
    "    prob_fail_on_task = prod_arr\n",
    "    return (prob_succ*total_time\n",
    "           + np.sum(prob_fail_on_task*exp_time_given_fail_on_task))\n",
    "\n",
    "\n",
    "\n",
    "def expand_to_lower_tri_mat(arr):\n",
    "    '''Converts arr to a lower triangular matrix.\n",
    "    e.g. [1,2,3] => [[1,0,0]\n",
    "                     [1,2,0]\n",
    "                     [1,2,3]]'''\n",
    "    two_d_arr = np.expand_dims((arr), 0)\n",
    "    square_mat = np.repeat(two_d_arr,\n",
    "                             repeats=arr.shape[0],\n",
    "                             axis=0)\n",
    "    return np.tril(square_mat)\n",
    "    \n",
    "def prob_prod_arr(prob_mat, prob_col):\n",
    "    '''Returns the product array that will satisfy the\n",
    "    equation in the appendix e.g. \n",
    "    prob_mat = [[0.8, 0.0, 0.0],    prob_col = [0.2, 0.3, 0.4]\n",
    "                [0.8, 0.7, 0.0],\n",
    "                [0.8, 0.7, 0.6]]\n",
    "    => prod_arr = column product of( [[0.8, 0.0, 0.0], \n",
    "                                     [0.8, 0.7, 0.0],\n",
    "                                     [0.8, 0.7, 0.6]]                    \n",
    "                                    +[[0.2, 0.0, 0.0],\n",
    "                                      [0.0, 0.3, 0.0],\n",
    "                                      [0.0, 0.0, 0.4]] \n",
    "                                    +[[0.0, 1.0, 1,0],\n",
    "                                      [0.0, 0.0, 1.0],\n",
    "                                      [0.0, 0.0, 0.0]] )\n",
    "      which equals [0.2  , 0.24 , 0.224]'''                              \n",
    "    np.fill_diagonal(prob_mat, 0)\n",
    "    ones = np.triu(np.ones(np.shape(prob_mat)))\n",
    "    np.fill_diagonal(ones, 0)\n",
    "    return np.prod(ones + prob_mat + np.diag(prob_col), 1)\n",
    "\n",
    "def sum_times(time_mat):\n",
    "    '''Returns an array of sums from\n",
    "    a lower triangular matrix after zeroing\n",
    "    diagonal'''\n",
    "    np.fill_diagonal(time_mat, 0)\n",
    "    return np.sum(time_mat, 1)\n",
    "\n",
    "def present_task_names(arr, df):\n",
    "    '''Creates DataFrame of task names from task rows'''\n",
    "    name_list = []\n",
    "    row_to_name = row_to_name_dict(df)\n",
    "    for row in arr:\n",
    "        name_list.append(row_to_name[row])\n",
    "    return pd.DataFrame(name_list, columns=[\"Task\"])\n",
    "\n",
    "    \n",
    "def plot_fig(sorted_sums, hist_vals):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 8))\n",
    "    axs[0].plot(np.arange(len(sorted_sums)), sorted_sums, color='black', ls='--')\n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_ylabel('Time')\n",
    "    axs[0].set_title('Expected time with respect to \\n order of tasks')\n",
    "    axs[1].hist(hist_vals, bins=30)\n",
    "    axs[1].set_title('Approximate distribution of occurence of failure')\n",
    "    axs[1].set_xlabel(\"Time\")\n",
    "    axs[1].set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "def simulate_failures(df, index):\n",
    "    totals = []\n",
    "    prob = df['Probability'].values.astype(float)[index]\n",
    "    time = df['Time'].values.astype(float)[index]\n",
    "    lambdas = get_lambdas(time, prob)\n",
    "    success_count = 50000\n",
    "    prior_task_time = 0\n",
    "    for j, rate in enumerate(lambdas):\n",
    "        trials = RV(Exponential(rate=rate)).sim(success_count)\n",
    "        failed = trials.filter_leq(time[j])\n",
    "        totals.append(np.array(list(failed)) + prior_task_time)\n",
    "        success_count = len(trials) - len(failed)\n",
    "        prior_task_time += time[j]\n",
    "    totals = np.hstack(totals)\n",
    "    return totals\n",
    "\n",
    "def get_lambdas(time, prob):\n",
    "    return 1/time*np.log(1/(1 - prob))\n",
    "\n",
    "def main(df):\n",
    "    df = switch_from_names(df)\n",
    "    deps = df.filter(like='D').values\n",
    "    times = df['Time'].values.astype(float)\n",
    "    probs = df['Probability'].values.astype(float)\n",
    "    perms = gen_perms(df)\n",
    "    valid_perms = validate_perms(perms, deps)\n",
    "    sums = get_expected_times(valid_perms, df)\n",
    "    sorted_sums = np.sort(sums)\n",
    "    best_order = valid_perms[np.argmin(sums)]\n",
    "    best_df = present_task_names(best_order, df)\n",
    "    best_index = best_df.replace(\n",
    "        name_to_row_dict(df)).values.flatten() - 1\n",
    "    hist_vals = simulate_failures(df, best_index)\n",
    "    printmd(\"## Report\")\n",
    "    printmd(\"##### The optimal order is \")\n",
    "    display(best_df)\n",
    "    printmd(\"##### The expected time you will work on this project is\")\n",
    "    printmd(\"##### \" + str(sorted_sums[0]))\n",
    "    printmd(\"##### and the probability you will succeed is\")\n",
    "    printmd(\"##### \" + str(np.prod(1 - probs)) + \".\")\n",
    "    plot_fig(sorted_sums, hist_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How it works:\n",
    "1. If you have previously used this app to build a sheet and you have the file saved, you can pick up where you left off by uploading it. Simply upload the file and click Build Sheet.\n",
    "2. To start with a blank sheet, just click Build Sheet.\n",
    "3. Fill the Tasks column with short names for each task, the Time column with your estimation for how long each task will take, and the Probability column with your estimation of the probability that each task will fail.\n",
    "    1. Probabilities need to be numbers strictly greater than 0 and less than 1!\n",
    "4. Let's say you put task A in row 1. You would then put the names of any tasks that you must complete before you can attempt task A in the D columns on row 1.\n",
    "5. Click run to get a full report!\n",
    "6. Click the link at the bottom of the report to download your sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d178c5bec149daa87099ecac07ca02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.csv', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myupload = ipywidgets.FileUpload(accept='.csv', multiple=False)\n",
    "display(myupload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54d3c97ea494f7e97b2533db2dad340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Build Sheet', style=ButtonStyle()), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sheet_butt = ipywidgets.Button(description='Build Sheet')\n",
    "out = ipywidgets.Output()\n",
    "sheet = build_sheet()\n",
    "\n",
    "def sheet_butt_func(_):\n",
    "    global sheet\n",
    "    with out:\n",
    "        try:\n",
    "            clear_output()\n",
    "            uploaded_filename = next(iter(myupload.value))\n",
    "            content = myupload.value[uploaded_filename]['content']\n",
    "            with open('task_sheet.csv', 'wb') as f: f.write(content)\n",
    "            sheet = build_sheet()\n",
    "            display(sheet)\n",
    "        except:\n",
    "            sheet = build_sheet()\n",
    "            display(sheet)\n",
    "sheet_butt.on_click(sheet_butt_func)\n",
    "display(ipywidgets.VBox([sheet_butt,out]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ada3241c15c42f7aff47acd71c9570c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Run', style=ButtonStyle()),)), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = ipywidgets.Button(description='Run')\n",
    "out = ipywidgets.Output()\n",
    "def run_program(_):\n",
    "    with out:\n",
    "        df = df_from_sheet(sheet)\n",
    "        df.to_csv('task_sheet.csv', index=False)\n",
    "        local_file = FileLink('./task_sheet.csv', result_html_prefix=\"Click here to download the sheet: \")\n",
    "        return main(df), display(local_file)\n",
    "        \n",
    "run.on_click(run_program)\n",
    "buttons = ipywidgets.HBox([run])\n",
    "ipywidgets.VBox([buttons,out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by letting $T$ be a random variable representing the time we spend on the project, from the begining to the point where we either succeed or fail. Our goal is to minimize $\\text{E}[T]$.\n",
    "\n",
    "Let $L$ be a random variable indicating the task we fail on. We define $L$ as\n",
    "\n",
    "$$\n",
    "L = \\begin{cases} \n",
    "     i & \\text{we fail on task }i \\\\\n",
    "     0 & \\text{we succeed}. \\\\ \n",
    "   \\end{cases}\n",
    "$$\n",
    "\n",
    "We can now invoke the law of total expectation.\n",
    "\n",
    "$$\n",
    "\\text{E}[T] = \\text{E}[\\text{E}[T \\vert L]] = \\text{P}(L = 0)\\text{E}[T \\vert L = 0] + \\text{P}(L = 1)\\text{E}[T \\vert L = 1] + \\dots + \\text{P}(L = n)\\text{E}[T \\vert L = n].\n",
    "$$\n",
    "\n",
    "The user supplies us with their estimates of the probability of failure on each task, and their estimate for the time each task will take. We denote these as $p_1, \\dots p_n$ and $t_1, \\dots t_n$. For our purposes these are constant known values. It follows that\n",
    "\n",
    "$$\n",
    "\\text{P}(L = 0) = (1 - p_1) \\dots (1 - p_n) = \\prod_{i = 1}^n (1 - p_i) \\text{ and}\n",
    "$$\n",
    "$$\n",
    "\\text{E}[T \\vert L = 0] = t_1 + \\dots t_n = \\sum_{i = 1}^n t_i.\n",
    "$$\n",
    "Take $ i \\in [n]$. It's easy to see that\n",
    "$$\n",
    "\\text{P}(L = i) = (1 - p_1) \\dots (1 - p_{i - 1}) p_i = \\prod_{k = 1}^ {i - 1} (1 - p_k)p_i.\n",
    "$$\n",
    "\n",
    "It is not obvious what $\\text{E}[T \\vert L_{i}]$ should be, and that is because we lack enough information about the distribution of $T$. We have to make an assumption, and the one we choose is that the probability of failing during the next minute of doing a task is independent of how long we have been doing the task (see <a href = https://cs.stanford.edu/~jsteinhardt/ResearchasaStochasticDecisionProcess.html>Research as a Stocastic Decision Process</a>). This implies that $f_T$ is given by\n",
    "\n",
    "$$\n",
    "f_T(t) = \\begin{cases}\n",
    "            \\lambda_1 e^{-\\lambda_1 t} & 0 \\leq t < t_1 \\\\\n",
    "            (1 - p_1) \\lambda_2 e^{-\\lambda_2 (t - t_1)} & t_1 \\leq t < t_1 + t_2 \\\\\n",
    "            \\vdots & \\vdots \\\\\n",
    "           (1 - p_{i - 1}) \\dots (1 - p_1) \\lambda_i e^{-\\lambda_i( t -  t_1 - \\dots - t_{i - 1})} & t_1 + \\dots + t_{i - 1} \\leq t < t_1 + \\dots + t_{i} \\\\\n",
    "            \\vdots & \\vdots \\\\\n",
    "            (1 - p_{n}) \\dots (1 - p_{i}) \\dots (1 - p_1) \\lambda_n e^{-\\lambda_n (t - t_1 - \\dots -t_{n - 1})} & t_1 + \\dots + t_{i} + \\dots + t_{n - 1} \\leq t < t_1  + \\dots + t_{i} + \\dots + t_{n},\n",
    "       \\end{cases}\n",
    "$$\n",
    "\n",
    "where $\\lambda_{i}$ is the failure rate of task $i$ given by\n",
    "$$\n",
    "\\lambda_{i} = \\frac{1}{t_i}\\ln \\Big{(}\\frac{1}{1 - p_{i}}\\Big{)}.\n",
    "$$\n",
    "\n",
    "From this we have\n",
    "$$\n",
    "f_{T \\vert \\{L = i\\}}(t) = \\frac{f_T(t)}{\\text{P}(L = i)} = \\frac{(1 - p_{i - 1}) \\dots (1 - p_1) \\lambda_i e^{-\\lambda_i t -  t_1 - \\dots - t_{i - 1}}}{(1 - p_{i - 1}) \\dots (1 - p_1)p_i} = \\frac{ \\lambda_i e^{-\\lambda_i t -  t_1 - \\dots - t_{i - 1}}}{p_i} \\text{ when } t_1 + \\dots + t_{i - 1} \\leq t < t_1 + \\dots + t_{i}.\n",
    "$$\n",
    "\n",
    "Let $t_0 = t_1 + \\dots + t_{i - 1}$. By performing a change of variables $ t \\rightarrow t - t_0$ we have\n",
    "$$\n",
    "\\text{E}[T \\vert L = i] = \\frac{1}{p_i} \\int_0^{t_i} (t + t_0) \\lambda_i e^{-\\lambda_i t} dt,\n",
    "$$\n",
    "\n",
    "which after some simplification yields\n",
    "\n",
    "$$\n",
    "\\text{E}[T \\vert L = i] = \\frac{1 + \\lambda_i t_0 - e^{- \\lambda_i t_i } - \\lambda_i e^{ -\\lambda_i t_i } (t_0 + t_i)}{ \\lambda_i p_i}.\n",
    "$$\n",
    "\n",
    "Substituting in our value for $\\lambda_i$ and simplifying we have\n",
    "\n",
    "$$\n",
    "\\text{E}[T \\vert L = i] = t_0 - \\frac{t_i}{p_i} + \\frac{t_i}{\\ln \\big{(} \\frac{1}{1 - p_i} \\big{)} } + t_i.\n",
    "$$\n",
    "\n",
    "Combining this with what we found for $\\text{P}(L = i)$ and recalling that $t_0 = \\sum_{j = 1}^{i - 1} t_j$ we have\n",
    "\n",
    "$$\n",
    "\\text{P}(L = i)\\text{E}[T \\vert L = i] =  \\prod_{k = 1}^ {i - 1} (1 - p_k)p_i \\Bigg(\\sum_{j = 0}^{i - 1} t_j - \\frac{t_i}{p_i} + \\frac{t_i}{\\ln \\big{(} \\frac{1}{1 - p_i} \\big{)} } + t_i \\Bigg).\n",
    "$$\n",
    "\n",
    "Thus, our final expression for $ \\text{E}[T]$ is\n",
    "\n",
    "$$\n",
    "\\text{E}[T] = \\prod_{i = 1}^n (1 - p_i)\\sum_{i = 1}^n t_i + \\sum_{i = 1}^n \\Bigg( \\prod_{k = 1}^ {i - 1} (1 - p_k)p_i \\Bigg(\\sum_{j = 0}^{i - 1} t_j - \\frac{t_i}{p_i} + \\frac{t_i}{\\ln \\big{(} \\frac{1}{1 - p_i} \\big{)} } + t_i \\Bigg) \\Bigg).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
